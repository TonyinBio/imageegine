{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 256\n",
    "n_features = 128\n",
    "projection_dim = 128\n",
    "weight_decay = 1e-4\n",
    "lr = 1e-3\n",
    "\n",
    "n_channels = 5\n",
    "seq_len = 256\n",
    "n_classes = 10\n",
    "\n",
    "vis_freq = 10\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/\"\n",
    "# O1 O2 T5 T6\n",
    "# bandpass 5-95 Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "d_train = datasets.load_from_disk(data_dir + \"dataset_train_preprocessed\")\n",
    "d_test = datasets.load_from_disk(data_dir + \"dataset_test_preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eegs = torch.tensor(d_train[\"pixel_values\"])\n",
    "train_labels = torch.tensor(d_train[\"label\"])\n",
    "\n",
    "test_eegs = torch.tensor(d_test[\"pixel_values\"])\n",
    "test_labels = torch.tensor(d_test[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10436, 256, 5]) torch.float32\n",
      "torch.Size([10436]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(train_eegs.shape, train_eegs.dtype)\n",
    "print(train_labels.shape, train_labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, eegs, labels, transform=None):\n",
    "        self.eegs = eegs\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eeg = self.eegs[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            eeg = self.transform(eeg)\n",
    "\n",
    "        return eeg, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eegs)\n",
    "\n",
    "train_data = EEGDataset(train_eegs, train_labels)\n",
    "test_data = EEGDataset(test_eegs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 5]) tensor(6)\n"
     ]
    }
   ],
   "source": [
    "eeg, label = train_data[0]\n",
    "print(eeg.shape, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import EEGFeatNet, ClassificationHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 256, 5])\n",
      "torch.Size([256, 128])\n"
     ]
    }
   ],
   "source": [
    "eeg = torch.randn((batch_size, seq_len, n_channels)).to(device)\n",
    "print(eeg.shape)\n",
    "model = EEGFeatNet(n_channels=n_channels, n_features=n_features, projection_dim=projection_dim).to(device)\n",
    "\n",
    "classifier = ClassificationHead(projection_dim, 10)\n",
    "\n",
    "proj = model(eeg)\n",
    "print(proj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'All Parameters: 85504'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"All Parameters: {sum(p.numel() for p in model.parameters())}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 256, 5])\n"
     ]
    }
   ],
   "source": [
    "i, (eeg, label) = next(enumerate(train_loader))\n",
    "\n",
    "print(eeg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 128])\n"
     ]
    }
   ],
   "source": [
    "proj = model(eeg)\n",
    "print(proj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 128])\n"
     ]
    }
   ],
   "source": [
    "for eeg, label in train_loader:\n",
    "    eeg = eeg.to(device)\n",
    "    proj = model(eeg)\n",
    "    print(proj.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def train(epoch, model, optimizer, loss_fn, miner, train_dataloader, test_dataloader, accuracy_calculator):\n",
    "    tq = tqdm(train_dataloader)\n",
    "    for batch_idx, (eeg, label) in enumerate(tq, start=1):\n",
    "        eeg    = eeg.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_proj = model(eeg)\n",
    "\n",
    "        hard_pairs = miner(x_proj, label)\n",
    "        loss = loss_fn(x_proj, label, hard_pairs)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        tq.set_description('Train:[{}, {:0.3f}]'.format(epoch, loss.item()))\n",
    "\n",
    "    if (epoch % vis_freq) == 0:\n",
    "        acc = calc_accuracy(model, train_dataloader, test_dataloader, accuracy_calculator)\n",
    "        print(\"[Epoch: {}, Precision@1: {}]\".format(epoch, acc))\n",
    "\n",
    "def calc_accuracy(model, train_dataloader, test_dataloader, accuracy_calculator):\n",
    "    X_embeds, Y = get_embeddings_over_dataset(model, train_dataloader)\n",
    "    X_embeds_test, Y_test = get_embeddings_over_dataset(model, test_dataloader)\n",
    "    accuracies = accuracy_calculator.get_accuracy(\n",
    "        X_embeds_test, Y_test, X_embeds, Y, False\n",
    "    )\n",
    "\n",
    "    return accuracies[\"precision_at_1\"]\n",
    "\n",
    "def get_embeddings_over_dataset(\n",
    "    model,\n",
    "    loader\n",
    "    ):\n",
    "    \"\"\"Loop through a full dataset and return all embeddings.\n",
    "    \"\"\"\n",
    "    # Create a loader on the go\n",
    "\n",
    "    X_embeds, Y = [], []\n",
    "    for i, (x, y) in enumerate(tqdm(loader)):\n",
    "        x_embeds = get_embeddings(x, model)\n",
    "        X_embeds.append(x_embeds)\n",
    "        Y.append(y)\n",
    "\n",
    "    X_embeds = torch.cat(X_embeds, dim=0)\n",
    "    Y = torch.cat(Y, dim=0)\n",
    "    return X_embeds, Y\n",
    "        \n",
    "def get_embeddings(\n",
    "    x: torch.Tensor, \n",
    "    model: nn.Module, \n",
    "    ) -> torch.Tensor:\n",
    "    \"\"\"Calculate embeddings for a batch of images.\n",
    "    \"\"\"\n",
    "    #########################\n",
    "    # Finish Your Code HERE\n",
    "    # #########################\n",
    "\n",
    "    x_embeds = model(x)\n",
    "    \n",
    "    #########################\n",
    "\n",
    "    x_embeds = x_embeds.cpu()   # Cast to CPU\n",
    "    x_embeds = torch.nn.functional.normalize(x_embeds, dim=1)      # Extra Step: Normalize the embeddings\n",
    "    return x_embeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_metric_learning import miners, losses, distances\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
    "\n",
    "model = EEGFeatNet(n_channels=n_channels, n_features=n_features, projection_dim=projection_dim).to(device)\n",
    "optimizer = torch.optim.AdamW(list(model.parameters()), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "margin = 0.2\n",
    "distance = distances.LpDistance()\n",
    "loss_fn = losses.TripletMarginLoss(margin, distance=distance)\n",
    "miner = miners.TripletMarginMiner(margin, \"semihard\", distance=distance)\n",
    "\n",
    "accuracy_calculator = AccuracyCalculator(include=(\"precision_at_1\",), k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:[0, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.28it/s]\n",
      "100%|██████████| 41/41 [00:08<00:00,  5.07it/s]\n",
      "100%|██████████| 11/11 [00:02<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 0, Precision@1: 0.09946442234123948]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:[1, 0.135]: 100%|██████████| 41/41 [00:12<00:00,  3.23it/s]\n",
      "Train:[2, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.16it/s]\n",
      "Train:[3, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.22it/s]\n",
      "Train:[4, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.20it/s]\n",
      "Train:[5, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.23it/s]\n",
      "Train:[6, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.22it/s]\n",
      "Train:[7, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.24it/s]\n",
      "Train:[8, 0.000]: 100%|██████████| 41/41 [00:13<00:00,  3.08it/s]\n",
      "Train:[9, 0.000]: 100%|██████████| 41/41 [00:13<00:00,  3.14it/s]\n",
      "Train:[10, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.16it/s]\n",
      "100%|██████████| 41/41 [00:08<00:00,  5.12it/s]\n",
      "100%|██████████| 11/11 [00:02<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 10, Precision@1: 0.1009946442234124]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:[11, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.24it/s]\n",
      "Train:[12, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.23it/s]\n",
      "Train:[13, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.22it/s]\n",
      "Train:[14, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.24it/s]\n",
      "Train:[15, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.28it/s]\n",
      "Train:[16, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.27it/s]\n",
      "Train:[17, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.21it/s]\n",
      "Train:[18, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.25it/s]\n",
      "Train:[19, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.26it/s]\n",
      "Train:[20, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.24it/s]\n",
      "100%|██████████| 41/41 [00:07<00:00,  5.21it/s]\n",
      "100%|██████████| 11/11 [00:02<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 20, Precision@1: 0.09908186687069626]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:[21, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.26it/s]\n",
      "Train:[22, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.26it/s]\n",
      "Train:[23, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.24it/s]\n",
      "Train:[24, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.27it/s]\n",
      "Train:[25, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.28it/s]\n",
      "Train:[26, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.25it/s]\n",
      "Train:[27, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.26it/s]\n",
      "Train:[28, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.26it/s]\n",
      "Train:[29, 0.000]: 100%|██████████| 41/41 [00:13<00:00,  3.04it/s]\n",
      "Train:[30, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.19it/s]\n",
      "100%|██████████| 41/41 [00:07<00:00,  5.18it/s]\n",
      "100%|██████████| 11/11 [00:02<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 30, Precision@1: 0.09678653404743688]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:[31, 0.000]: 100%|██████████| 41/41 [00:12<00:00,  3.23it/s]\n",
      "Train:[32, 0.000]:  24%|██▍       | 10/41 [00:03<00:10,  2.89it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/sun/code/nathacks2023/eeg2image.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sun/code/nathacks2023/eeg2image.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_epochs):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sun/code/nathacks2023/eeg2image.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     train(epoch, model, optimizer, loss_fn, miner, train_loader, test_loader, accuracy_calculator)\n",
      "\u001b[1;32m/Users/sun/code/nathacks2023/eeg2image.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sun/code/nathacks2023/eeg2image.ipynb#X32sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m label \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sun/code/nathacks2023/eeg2image.ipynb#X32sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sun/code/nathacks2023/eeg2image.ipynb#X32sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m x_proj \u001b[39m=\u001b[39m model(eeg)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sun/code/nathacks2023/eeg2image.ipynb#X32sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m hard_pairs \u001b[39m=\u001b[39m miner(x_proj, label)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sun/code/nathacks2023/eeg2image.ipynb#X32sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(x_proj, label, hard_pairs)\n",
      "File \u001b[0;32m~/miniconda3/envs/cmput328/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/cmput328/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/sun/code/nathacks2023/eeg2image.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sun/code/nathacks2023/eeg2image.ipynb#X32sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m h_n \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sun/code/nathacks2023/eeg2image.ipynb#X32sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m c_n \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sun/code/nathacks2023/eeg2image.ipynb#X32sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m _, (h_n, c_n) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x, (h_n, c_n))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sun/code/nathacks2023/eeg2image.ipynb#X32sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m x \u001b[39m=\u001b[39m h_n[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sun/code/nathacks2023/eeg2image.ipynb#X32sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/cmput328/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/cmput328/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cmput328/lib/python3.10/site-packages/torch/nn/modules/rnn.py:879\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    876\u001b[0m         hx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    878\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    880\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    881\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    882\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    883\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    train(epoch, model, optimizer, loss_fn, miner, train_loader, test_loader, accuracy_calculator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmput328",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
